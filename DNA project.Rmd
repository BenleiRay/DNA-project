---
title: "DNA project"
author: "Ray"
date: "7/26/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#Package

```{r,warning=F,message=F}
library(pls)
library(tidyverse)
library(glmnet)
library(VIM)
library(ggplot2)
library(caret)
```


# 1. Data preparation

Load the data in
```{r}
#cpgs
geo_methylation <- readRDS("C:/Users/86159/desktop/Project 2/geo_methylation.RDS")

#age,sex and geo corhort
geo_samples <- readRDS("C:/Users/86159/desktop/Project 2/geo_samples.RDS")


```



Check if has any NAs, fortunately, there is no na
```{r}
any(is.na(geo_methylation))
```

These is some NAs in geo_samples
```{r}
any(is.na(geo_samples))
```


Missing index
```{r}
a <- which(is.na(geo_samples$Sex))
```

Only Sex has NA
```{r}
geo_samples[a,]
```



Only the corhort GSE53740 has NA
```{r}
unique(geo_samples[a,]$"GEO")
```


Combine the two data set
```{r}
combined.data <- cbind(geo_samples,geo_methylation)
```

Show all the cohorts' codes
```{r}
unique(combined.data$GEO)
```


Create 20 year age groups
```{r}
combined.data$AgeGroup <- cut(combined.data$Age, 
                         breaks = c(-Inf,20,40,60,80,Inf) ,
                         
                         labels = c("0-19 years"
                                    ,"20-39 years",
                                    "40-59 years","60-79 years"
                                    ,"80+ years"),
                         right = FALSE)
```



## 1.1 Delete the missing values


A na index
```{r}
na.idex.all <- which(is.na(combined.data$Sex))
```

select the obs without NAs
```{r}
combined.data <- combined.data[-na.idex.all,]
geo_methylation <- geo_methylation[-na.idex.all,]
geo_samples <- geo_samples[-na.idex.all,]
```




## 1.2 Training data and testing data

use leave one out to create training data set 
```{r}
x.train.data1 <- geo_methylation[which(combined.data$GEO != 'GSE40279'),]
x.train.data2 <- geo_methylation[which(combined.data$GEO != 'GSE41169'),]
x.train.data3 <- geo_methylation[which(combined.data$GEO != 'GSE42861'),]
x.train.data4 <- geo_methylation[which(combined.data$GEO != 'GSE53740'),]
x.train.data5 <- geo_methylation[which(combined.data$GEO != 'GSE72773'),]
x.train.data6 <- geo_methylation[which(combined.data$GEO != 'GSE72775'),]
x.train.data7 <- geo_methylation[which(combined.data$GEO != 'GSE72777'),]
x.train.data8 <- geo_methylation[which(combined.data$GEO != 'GSE78874'),]

y.train.data1 <- combined.data %>%
  filter(GEO != 'GSE40279') %>%
  select(Age,Sex,AgeGroup)

y.train.data2 <- combined.data %>%
  filter(GEO != 'GSE41169') %>%
  select(Age,Sex,AgeGroup)

y.train.data3 <- combined.data %>%
  filter(GEO != 'GSE42861') %>%
  select(Age,Sex,AgeGroup)

y.train.data4 <- combined.data %>%
  filter(GEO != 'GSE53740') %>%
  select(Age,Sex,AgeGroup)

y.train.data5 <- combined.data %>%
  filter(GEO != 'GSE72773') %>%
  select(Age,Sex,AgeGroup) 

y.train.data6 <- combined.data %>%
  filter(GEO != 'GSE72775') %>%
  select(Age,Sex,AgeGroup)

y.train.data7 <- combined.data %>%
  filter(GEO != 'GSE72777') %>%
  select(Age,Sex,AgeGroup)

y.train.data8 <- combined.data %>%
  filter(GEO != 'GSE78874') %>%
  select(Age,Sex,AgeGroup)

```


use leave one out to create testing data set 
```{r}
x.test.data1 <- geo_methylation[which(combined.data$GEO == 'GSE40279'),]
x.test.data2 <- geo_methylation[which(combined.data$GEO == 'GSE41169'),]
x.test.data3 <- geo_methylation[which(combined.data$GEO == 'GSE42861'),]
x.test.data4 <- geo_methylation[which(combined.data$GEO == 'GSE53740'),]
x.test.data5 <- geo_methylation[which(combined.data$GEO == 'GSE72773'),]
x.test.data6<- geo_methylation[which(combined.data$GEO == 'GSE72775'),]
x.test.data7 <- geo_methylation[which(combined.data$GEO == 'GSE72777'),]
x.test.data8 <- geo_methylation[which(combined.data$GEO == 'GSE78874'),]

y.test.data1 <- combined.data %>%
  filter(GEO == 'GSE40279') %>%
  select(Age,Sex,AgeGroup)

y.test.data2 <- combined.data %>%
  filter(GEO == 'GSE41169') %>%
  select(Age,Sex,AgeGroup)

y.test.data3 <- combined.data %>%
  filter(GEO == 'GSE42861') %>%
  select(Age,Sex,AgeGroup)

y.test.data4 <- combined.data %>%
  filter(GEO == 'GSE53740') %>%
  select(Age,Sex,AgeGroup)

y.test.data5 <- combined.data %>%
  filter(GEO == 'GSE72773') %>%
  select(Age,Sex,AgeGroup)

y.test.data6 <- combined.data %>%
  filter(GEO == 'GSE72775') %>%
  select(Age,Sex,AgeGroup)

y.test.data7 <- combined.data %>%
  filter(GEO == 'GSE72777') %>%
  select(Age,Sex,AgeGroup)

y.test.data8 <- combined.data %>%
  filter(GEO == 'GSE78874') %>%
  select(Age,Sex,AgeGroup)

```

# 2. EDA

Calculate the percentage for male and female
```{r}
df <- combined.data %>% 
  group_by(Sex) %>% # Variable to be transformed
  count() %>% 
  ungroup() %>% 
  mutate(perc = `n` / sum(`n`)) %>% 
  arrange(perc) %>%
  mutate(labels = scales::percent(perc))
```

Pie chart for Sex variable
```{r}
ggplot(df, aes(x = "", y = perc, fill = Sex)) +
  geom_col(color = "black") +
  geom_label(aes(label = labels),
            position = position_stack(vjust = 0.5),
            show.legend = FALSE) +
  guides(fill = guide_legend(title = "Sex")) +
  scale_fill_brewer() +
  coord_polar(theta = "y") + 
  theme_void() +
  ggtitle("Figure 3.1 Pie chart for Sex")
```





Historgram for age distribution by sex
```{r}
  ggplot(combined.data,aes(x = Age)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(Sex ~ ., scales = "free") +
  ggtitle("Figure 3.2 Histogram for age distribution by sex")
```



Barplot for different age groups by sex
```{r}
pl <- ggplot(data = combined.data,aes(x = AgeGroup, fill =AgeGroup ))
pl <- pl + geom_bar()
pl <- pl + theme_minimal()
pl <- pl  + theme(axis.text.x = element_text(angle = 90,hjust =0 ))
pl <- pl + facet_grid(Sex ~ ., scales = "free")
pl <- pl + ggtitle("Figure 3.3 Barplot for different age groups by sex")
pl
```



Barplot for different age groups
```{r}
pl <- ggplot(data = combined.data,aes(x = AgeGroup, fill =AgeGroup ))
pl <- pl + geom_bar()
pl <- pl + theme_minimal()
pl <- pl  + theme(axis.text.x = element_text(angle = 90,hjust =0 ))
pl <- pl + ggtitle("Figure 3.4 Barplot for different age groups")
pl
```

A data frame showing the percentage of specific sex-agegroup
```{r}
dfs <- combined.data %>% 
  group_by(Sex, AgeGroup) %>% # Variable to be transformed
  count() %>% 
  ungroup() %>% 
  mutate(perc = `n` / sum(`n`)) %>% 
  arrange(perc) %>%
  mutate(labels = scales::percent(perc)) %>%
  arrange(Sex,AgeGroup)
```


Shows the results
```{r}
dfs
```


Write it to a csv file
```{r}
write.csv(dfs, "EDA.csv")
```


# 3. Model

## 3.1 Baseline model

### 3.1.1 Preparation
```{r}
# Sanity check for training data sets
identical(rownames(x.train.data1), rownames(y.train.data1))
identical(rownames(x.train.data2), rownames(y.train.data2))
identical(rownames(x.train.data3), rownames(y.train.data3))
identical(rownames(x.train.data4), rownames(y.train.data4))
identical(rownames(x.train.data5), rownames(y.train.data5))
identical(rownames(x.train.data6), rownames(y.train.data6))
identical(rownames(x.train.data7), rownames(y.train.data7))
identical(rownames(x.train.data8), rownames(y.train.data8))
```



```{r}
# Sanity check for testing data sets
identical(rownames(x.test.data1), rownames(y.test.data1))
identical(rownames(x.test.data2), rownames(y.test.data2))
identical(rownames(x.test.data3), rownames(y.test.data3))
identical(rownames(x.test.data4), rownames(y.test.data4))
identical(rownames(x.test.data5), rownames(y.test.data5))
identical(rownames(x.test.data6), rownames(y.test.data6))
identical(rownames(x.test.data7), rownames(y.test.data7))
identical(rownames(x.test.data8), rownames(y.test.data8))

```


Create a list for 8 training data sets
```{r}
list.train.x <- list(x.train.data1,x.train.data2,x.train.data3,x.train.data4,x.train.data5,x.train.data6,x.train.data7,x.train.data8)

list.train.y <- list(y.train.data1,y.train.data2,y.train.data3,y.train.data4,y.train.data5,y.train.data6,y.train.data7,y.train.data8)
```

Create a list for 8 testing data sets
```{r}
list.test.x <- list(x.test.data1,x.test.data2,x.test.data3,x.test.data4,x.test.data5,x.test.data6,x.test.data7,x.test.data8)

list.test.y <- list(y.test.data1,y.test.data2,y.test.data3,y.test.data4,y.test.data5,y.test.data6,y.test.data7,y.test.data8) 
```

### 3.1.2 Modeling

A baseline model using leave one out 
```{r}
set.seed(24)
list.of.coefs <- list()
list.of.fits.baseline <- list()
for (i in 1:8) {
# Cross validation to get best lambda
elnet.cv <- cv.glmnet(list.train.x[[i]], list.train.y[[i]]$Age, family="gaussian", alpha = 0.5, nfolds=10)

# Now get best model with defined parameters
fit <- glmnet(list.train.x[[i]], list.train.y[[i]]$Age, family = "gaussian", alpha = 0.5, lambda = elnet.cv$lambda.min)

#save the model in the list
list.of.fits.baseline[[i]] <- fit

coefs <- coef(fit)

# Remove coefficients that are 0
coefs <- as.data.frame(coefs[which(coefs!=0),])

# Tidy naming and export
names(coefs)[1] <- "Coefficient"
coefs$CpG <- rownames(coefs)
coefs <- coefs[,c("CpG", "Coefficient")]

list.of.coefs[[i]] <- coefs

}
```





### 3.1.3 Prediction

Predictions for 8 different cohorts
```{r}
list.of.pred.baseline <- list()
for (i in 1:8) {
list.of.pred.baseline[[i]] <- predict(list.of.fits.baseline[[i]],newx = list.test.x[[i]])

}
```


RMSE for 8 different cohorts
```{r}
list.of.RMSE.baseline <- c()
for (i in 1:8) {
list.of.RMSE.baseline[i] <- RMSE(list.of.pred.baseline[[i]],list.test.y[[i]]$Age)
}

list.of.RMSE.baseline
```


r for 8 different cohorts
```{r}
list.of.r.baseline <- c()
for (i in 1:8) {
list.of.r.baseline[i] <- cor(list.of.pred.baseline[[i]],list.test.y[[i]]$Age)
}

list.of.r.baseline
```



prediction for the whole data set
```{r}
pred.baseline.for.all <- rbind(list.of.pred.baseline[[1]],list.of.pred.baseline[[2]],list.of.pred.baseline[[3]],list.of.pred.baseline[[4]],list.of.pred.baseline[[5]],list.of.pred.baseline[[6]],list.of.pred.baseline[[7]],list.of.pred.baseline[[8]])
```

Sanity check for prediction data sets
```{r}
identical(rownames(pred.baseline.for.all), rownames(geo_samples))
```

Overall RMSE
```{r}
RMSE(pred.baseline.for.all,geo_samples$Age)
```

### 3.1.4 Plot

creata a corhort name to refer later
```{r}
cohort.name <- unique(geo_samples$GEO)
```

plot the pediction performance for each cohort
```{r}
par(mfrow = c(2, 4))
for (i in 1:8) {
plot(list.of.pred.baseline[[i]], list.test.y[[i]]$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[i],col=i+1,pch=19)
legend("topleft", legend=paste("r =",round(list.of.r.baseline[i],3),"(pv = 0.0)","\nRMSE =",round(list.of.RMSE.baseline[i],3)),bty = "n", pch=19, col=i+1,cex=0.63)
abline(a = 0, b = 1, lwd=2)

}


par()
```

plot the overall prediction performance
```{r}
plot(pred.baseline.for.all, geo_samples$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.baseline.for.all,geo_samples$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.baseline.for.all,geo_samples$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)
```

### 3.1.5 Plot by sex

select the male and female data
```{r}
pred.baseline.for.all.male <- pred.baseline.for.all[geo_samples$Sex=="M",]
pred.baseline.for.all.female <- pred.baseline.for.all[geo_samples$Sex=="F",]
```

plot the prediction by sex
```{r}
par(mfrow = c(1, 2))

plot(pred.baseline.for.all.male, geo_samples[geo_samples$Sex=="M",]$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data (male)",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.baseline.for.all.male,geo_samples[geo_samples$Sex=="M",]$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.baseline.for.all.male,geo_samples[geo_samples$Sex=="M",]$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)


plot(pred.baseline.for.all.female, geo_samples[geo_samples$Sex=="F",]$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data (female)",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.baseline.for.all.female,geo_samples[geo_samples$Sex=="F",]$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.baseline.for.all.female,geo_samples[geo_samples$Sex=="F",]$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)
```


###3.1.6 sex added model

add a sex code
```{r}


y.train.data1$sex.code <- ifelse(y.train.data1$Sex=='M',0,1)
y.train.data2$sex.code <- ifelse(y.train.data2$Sex=='M',0,1)
y.train.data3$sex.code <- ifelse(y.train.data3$Sex=='M',0,1)
y.train.data4$sex.code <- ifelse(y.train.data4$Sex=='M',0,1)
y.train.data5$sex.code <- ifelse(y.train.data5$Sex=='M',0,1)
y.train.data6$sex.code <- ifelse(y.train.data6$Sex=='M',0,1)
y.train.data7$sex.code <- ifelse(y.train.data7$Sex=='M',0,1)
y.train.data8$sex.code <- ifelse(y.train.data8$Sex=='M',0,1)
```

add a sex code
```{r}
y.test.data1$sex.code <- ifelse(y.test.data1$Sex=='M',0,1)
y.test.data2$sex.code <- ifelse(y.test.data2$Sex=='M',0,1)
y.test.data3$sex.code <- ifelse(y.test.data3$Sex=='M',0,1)
y.test.data4$sex.code <- ifelse(y.test.data4$Sex=='M',0,1)
y.test.data5$sex.code <- ifelse(y.test.data5$Sex=='M',0,1)
y.test.data6$sex.code <- ifelse(y.test.data6$Sex=='M',0,1)
y.test.data7$sex.code <- ifelse(y.test.data7$Sex=='M',0,1)
y.test.data8$sex.code <- ifelse(y.test.data8$Sex=='M',0,1)
```


copy the list
```{r}
list.train.x.sex <- list.train.x

list.test.x.sex <- list.test.x
```

create a new list for modeling
```{r}
list.train.x.sex[[1]] <- cbind(list.train.x.sex[[1]],y.train.data1$sex.code)
list.train.x.sex[[2]] <- cbind(list.train.x.sex[[2]],y.train.data2$sex.code)
list.train.x.sex[[3]] <- cbind(list.train.x.sex[[3]],y.train.data3$sex.code)
list.train.x.sex[[4]] <- cbind(list.train.x.sex[[4]],y.train.data4$sex.code)
list.train.x.sex[[5]] <- cbind(list.train.x.sex[[5]],y.train.data5$sex.code)
list.train.x.sex[[6]] <- cbind(list.train.x.sex[[6]],y.train.data6$sex.code)
list.train.x.sex[[7]] <- cbind(list.train.x.sex[[7]],y.train.data7$sex.code)
list.train.x.sex[[8]] <- cbind(list.train.x.sex[[8]],y.train.data8$sex.code)
```

create a new list for modeling
```{r}
list.test.x.sex[[1]] <- cbind(list.test.x.sex[[1]],y.test.data1$sex.code)
list.test.x.sex[[2]] <- cbind(list.test.x.sex[[2]],y.test.data2$sex.code)
list.test.x.sex[[3]] <- cbind(list.test.x.sex[[3]],y.test.data3$sex.code)
list.test.x.sex[[4]] <- cbind(list.test.x.sex[[4]],y.test.data4$sex.code)
list.test.x.sex[[5]] <- cbind(list.test.x.sex[[5]],y.test.data5$sex.code)
list.test.x.sex[[6]] <- cbind(list.test.x.sex[[6]],y.test.data6$sex.code)
list.test.x.sex[[7]] <- cbind(list.test.x.sex[[7]],y.test.data7$sex.code)
list.test.x.sex[[8]] <- cbind(list.test.x.sex[[8]],y.test.data8$sex.code)
```


change the column name
```{r}
colnames(list.train.x.sex[[1]])[23759] <- "sex"
colnames(list.train.x.sex[[2]])[23759] <- "sex"
colnames(list.train.x.sex[[3]])[23759] <- "sex"
colnames(list.train.x.sex[[4]])[23759] <- "sex"
colnames(list.train.x.sex[[5]])[23759] <- "sex"
colnames(list.train.x.sex[[6]])[23759] <- "sex"
colnames(list.train.x.sex[[7]])[23759] <- "sex"
colnames(list.train.x.sex[[8]])[23759] <- "sex"
```

change the column name
```{r}
colnames(list.test.x.sex[[1]])[23759] <- "sex"
colnames(list.test.x.sex[[2]])[23759] <- "sex"
colnames(list.test.x.sex[[3]])[23759] <- "sex"
colnames(list.test.x.sex[[4]])[23759] <- "sex"
colnames(list.test.x.sex[[5]])[23759] <- "sex"
colnames(list.test.x.sex[[6]])[23759] <- "sex"
colnames(list.test.x.sex[[7]])[23759] <- "sex"
colnames(list.test.x.sex[[8]])[23759] <- "sex"
```

a new model added sex
```{r}
set.seed(24)
list.of.coefs.sex <- list()
list.of.fits.baseline.sex <- list()
for (i in 1:8) {
# Cross validation to get best lambda
elnet.cv <- cv.glmnet(list.train.x.sex[[i]], list.train.y[[i]]$Age, family="gaussian", alpha = 0.5, nfolds=10)

# Now get best model with defined parameters
fit <- glmnet(list.train.x.sex[[i]], list.train.y[[i]]$Age, family = "gaussian", alpha = 0.5, lambda = elnet.cv$lambda.min)

#save the model in the list
list.of.fits.baseline.sex[[i]] <- fit

coefs <- coef(fit)

# Remove coefficients that are 0
coefs <- as.data.frame(coefs[which(coefs!=0),])

# Tidy naming and export
names(coefs)[1] <- "Coefficient"
coefs$CpG <- rownames(coefs)
coefs <- coefs[,c("CpG", "Coefficient")]

list.of.coefs.sex[[i]] <- coefs

}
```


Predictions for 8 different cohorts
```{r}
list.of.pred.baseline.sex <- list()
for (i in 1:8) {
list.of.pred.baseline.sex[[i]] <- predict(list.of.fits.baseline.sex[[i]],newx = list.test.x.sex[[i]])

}
```


RMSE for 8 different cohorts
```{r}
list.of.RMSE.baseline.sex <- c()
for (i in 1:8) {
list.of.RMSE.baseline.sex[i] <- RMSE(list.of.pred.baseline.sex[[i]],list.test.y[[i]]$Age)
}

list.of.RMSE.baseline.sex
```


r for 8 different cohorts
```{r}
list.of.r.baseline.sex <- c()
for (i in 1:8) {
list.of.r.baseline.sex[i] <- cor(list.of.pred.baseline.sex[[i]],list.test.y[[i]]$Age)
}

list.of.r.baseline.sex
```



prediction for the whole data set
```{r}
pred.baseline.for.all.sex <- rbind(list.of.pred.baseline.sex[[1]],list.of.pred.baseline.sex[[2]],list.of.pred.baseline.sex[[3]],list.of.pred.baseline.sex[[4]],list.of.pred.baseline.sex[[5]],list.of.pred.baseline.sex[[6]],list.of.pred.baseline.sex[[7]],list.of.pred.baseline.sex[[8]])
```

Sanity check for prediction data sets
```{r}
identical(rownames(pred.baseline.for.all.sex), rownames(geo_samples))
```

Overall RMSE
```{r}
RMSE(pred.baseline.for.all.sex,geo_samples$Age)
```
prediction by sex
```{r}
pred.baseline.for.all.sex.male <- pred.baseline.for.all.sex[geo_samples$Sex=="M",]
pred.baseline.for.all.sex.female <- pred.baseline.for.all.sex[geo_samples$Sex=="F",]
```

plot prediction by sex
```{r}
par(mfrow = c(1, 2))

plot(pred.baseline.for.all.sex.male, geo_samples[geo_samples$Sex=="M",]$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data sex added (male) ",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.baseline.for.all.sex.male,geo_samples[geo_samples$Sex=="M",]$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.baseline.for.all.sex.male,geo_samples[geo_samples$Sex=="M",]$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)


plot(pred.baseline.for.all.sex.female, geo_samples[geo_samples$Sex=="F",]$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data sex added (female)",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.baseline.for.all.sex.female,geo_samples[geo_samples$Sex=="F",]$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.baseline.for.all.sex.female,geo_samples[geo_samples$Sex=="F",]$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)
```

plot the overall prediction
```{r}
plot(pred.baseline.for.all.sex, geo_samples$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data sex added",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.baseline.for.all.sex,geo_samples$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.baseline.for.all.sex,geo_samples$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)
```


### 3.1.7 Sex separated

#### Data preparation

The index of male and female
```{r}
Male.index <- which(combined.data$Sex == 'M')

Female.index <- which(combined.data$Sex == 'F')
```


select the male data and female data
```{r}
Male.data <- combined.data[Male.index,]

Female.data <- combined.data[Female.index,]
```


#### Training data and testing data



use leave one out to create training data set for male and female
```{r}
Male.x.train.data1 <- x.train.data1[which(y.train.data1$Sex == 'M'),]
Male.x.train.data2 <- x.train.data2[which(y.train.data2$Sex == 'M'),]
Male.x.train.data3 <- x.train.data3[which(y.train.data3$Sex == 'M'),]
Male.x.train.data4 <- x.train.data4[which(y.train.data4$Sex == 'M'),]
Male.x.train.data5 <- x.train.data5[which(y.train.data5$Sex == 'M'),]
Male.x.train.data6 <- x.train.data6[which(y.train.data6$Sex == 'M'),]
Male.x.train.data7 <- x.train.data7[which(y.train.data7$Sex == 'M'),]
Male.x.train.data8 <- x.train.data8[which(y.train.data8$Sex == 'M'),]

Female.x.train.data1 <- x.train.data1[which(y.train.data1$Sex == 'F'),]
Female.x.train.data2 <- x.train.data2[which(y.train.data2$Sex == 'F'),]
Female.x.train.data3 <- x.train.data3[which(y.train.data3$Sex == 'F'),]
Female.x.train.data4 <- x.train.data4[which(y.train.data4$Sex == 'F'),]
Female.x.train.data5 <- x.train.data5[which(y.train.data5$Sex == 'F'),]
Female.x.train.data6 <- x.train.data6[which(y.train.data6$Sex == 'F'),]
Female.x.train.data7 <- x.train.data7[which(y.train.data7$Sex == 'F'),]
Female.x.train.data8 <- x.train.data8[which(y.train.data8$Sex == 'F'),]


Male.y.train.data1 <- y.train.data1[which(y.train.data1$Sex == 'M'),]
Male.y.train.data2 <- y.train.data2[which(y.train.data2$Sex == 'M'),]
Male.y.train.data3 <- y.train.data3[which(y.train.data3$Sex == 'M'),]
Male.y.train.data4 <- y.train.data4[which(y.train.data4$Sex == 'M'),]
Male.y.train.data5 <- y.train.data5[which(y.train.data5$Sex == 'M'),]
Male.y.train.data6 <- y.train.data6[which(y.train.data6$Sex == 'M'),]
Male.y.train.data7 <- y.train.data7[which(y.train.data7$Sex == 'M'),]
Male.y.train.data8 <- y.train.data8[which(y.train.data8$Sex == 'M'),]

Female.y.train.data1 <- y.train.data1[which(y.train.data1$Sex == 'F'),]
Female.y.train.data2 <- y.train.data2[which(y.train.data2$Sex == 'F'),]
Female.y.train.data3 <- y.train.data3[which(y.train.data3$Sex == 'F'),]
Female.y.train.data4 <- y.train.data4[which(y.train.data4$Sex == 'F'),]
Female.y.train.data5 <- y.train.data5[which(y.train.data5$Sex == 'F'),]
Female.y.train.data6 <- y.train.data6[which(y.train.data6$Sex == 'F'),]
Female.y.train.data7 <- y.train.data7[which(y.train.data7$Sex == 'F'),]
Female.y.train.data8 <- y.train.data8[which(y.train.data8$Sex == 'F'),]


```


use leave one out to create testing data set for male and female
```{r}
Male.x.test.data1 <- x.test.data1[which(y.test.data1$Sex == 'M'),]
Male.x.test.data2 <- x.test.data2[which(y.test.data2$Sex == 'M'),]
Male.x.test.data3 <- x.test.data3[which(y.test.data3$Sex == 'M'),]
Male.x.test.data4 <- x.test.data4[which(y.test.data4$Sex == 'M'),]
Male.x.test.data5 <- x.test.data5[which(y.test.data5$Sex == 'M'),]
Male.x.test.data6 <- x.test.data6[which(y.test.data6$Sex == 'M'),]
Male.x.test.data7 <- x.test.data7[which(y.test.data7$Sex == 'M'),]
Male.x.test.data8 <- x.test.data8[which(y.test.data8$Sex == 'M'),]

Female.x.test.data1 <- x.test.data1[which(y.test.data1$Sex == 'F'),]
Female.x.test.data2 <- x.test.data2[which(y.test.data2$Sex == 'F'),]
Female.x.test.data3 <- x.test.data3[which(y.test.data3$Sex == 'F'),]
Female.x.test.data4 <- x.test.data4[which(y.test.data4$Sex == 'F'),]
Female.x.test.data5 <- x.test.data5[which(y.test.data5$Sex == 'F'),]
Female.x.test.data6 <- x.test.data6[which(y.test.data6$Sex == 'F'),]
Female.x.test.data7 <- x.test.data7[which(y.test.data7$Sex == 'F'),]
Female.x.test.data8 <- x.test.data8[which(y.test.data8$Sex == 'F'),]

Male.y.test.data1 <- y.test.data1[which(y.test.data1$Sex == 'M'),]
Male.y.test.data2 <- y.test.data2[which(y.test.data2$Sex == 'M'),]
Male.y.test.data3 <- y.test.data3[which(y.test.data3$Sex == 'M'),]
Male.y.test.data4 <- y.test.data4[which(y.test.data4$Sex == 'M'),]
Male.y.test.data5 <- y.test.data5[which(y.test.data5$Sex == 'M'),]
Male.y.test.data6 <- y.test.data6[which(y.test.data6$Sex == 'M'),]
Male.y.test.data7 <- y.test.data7[which(y.test.data7$Sex == 'M'),]
Male.y.test.data8 <- y.test.data8[which(y.test.data8$Sex == 'M'),]

Female.y.test.data1 <- y.test.data1[which(y.test.data1$Sex == 'F'),]
Female.y.test.data2 <- y.test.data2[which(y.test.data2$Sex == 'F'),]
Female.y.test.data3 <- y.test.data3[which(y.test.data3$Sex == 'F'),]
Female.y.test.data4 <- y.test.data4[which(y.test.data4$Sex == 'F'),]
Female.y.test.data5 <- y.test.data5[which(y.test.data5$Sex == 'F'),]
Female.y.test.data6 <- y.test.data6[which(y.test.data6$Sex == 'F'),]
Female.y.test.data7 <- y.test.data7[which(y.test.data7$Sex == 'F'),]
Female.y.test.data8 <- y.test.data8[which(y.test.data8$Sex == 'F'),]
```

Sanity check for training data sets
```{r}
identical(rownames(Male.x.train.data1), rownames(Male.y.train.data1))
identical(rownames(Male.x.train.data2), rownames(Male.y.train.data2))
identical(rownames(Male.x.train.data3), rownames(Male.y.train.data3))
identical(rownames(Male.x.train.data4), rownames(Male.y.train.data4))
identical(rownames(Male.x.train.data5), rownames(Male.y.train.data5))
identical(rownames(Male.x.train.data6), rownames(Male.y.train.data6))
identical(rownames(Male.x.train.data7), rownames(Male.y.train.data7))
identical(rownames(Male.x.train.data8), rownames(Male.y.train.data8))

identical(rownames(Female.x.train.data1), rownames(Female.y.train.data1))
identical(rownames(Female.x.train.data2), rownames(Female.y.train.data2))
identical(rownames(Female.x.train.data3), rownames(Female.y.train.data3))
identical(rownames(Female.x.train.data4), rownames(Female.y.train.data4))
identical(rownames(Female.x.train.data5), rownames(Female.y.train.data5))
identical(rownames(Female.x.train.data6), rownames(Female.y.train.data6))
identical(rownames(Female.x.train.data7), rownames(Female.y.train.data7))
identical(rownames(Female.x.train.data8), rownames(Female.y.train.data8))
```

Sanity check for testing data sets
```{r}
identical(rownames(Male.x.test.data1), rownames(Male.y.test.data1))
identical(rownames(Male.x.test.data2), rownames(Male.y.test.data2))
identical(rownames(Male.x.test.data3), rownames(Male.y.test.data3))
identical(rownames(Male.x.test.data4), rownames(Male.y.test.data4))
identical(rownames(Male.x.test.data5), rownames(Male.y.test.data5))
identical(rownames(Male.x.test.data6), rownames(Male.y.test.data6))
identical(rownames(Male.x.test.data7), rownames(Male.y.test.data7))
identical(rownames(Male.x.test.data8), rownames(Male.y.test.data8))

identical(rownames(Female.x.test.data1), rownames(Female.y.test.data1))
identical(rownames(Female.x.test.data2), rownames(Female.y.test.data2))
identical(rownames(Female.x.test.data3), rownames(Female.y.test.data3))
identical(rownames(Female.x.test.data4), rownames(Female.y.test.data4))
identical(rownames(Female.x.test.data5), rownames(Female.y.test.data5))
identical(rownames(Female.x.test.data6), rownames(Female.y.test.data6))
identical(rownames(Female.x.test.data7), rownames(Female.y.test.data7))
identical(rownames(Female.x.test.data8), rownames(Female.y.test.data8))
```

Create a list for 8 training data sets for male and female
```{r}
Male.list.train.x <- list(Male.x.train.data1,Male.x.train.data2,Male.x.train.data3,Male.x.train.data4,Male.x.train.data5,Male.x.train.data6,Male.x.train.data7,Male.x.train.data8)

Male.list.train.y <- list(Male.y.train.data1,Male.y.train.data2,Male.y.train.data3,Male.y.train.data4,Male.y.train.data5,Male.y.train.data6,Male.y.train.data7,Male.y.train.data8)

Female.list.train.x <- list(Female.x.train.data1,Female.x.train.data2,Female.x.train.data3,Female.x.train.data4,Female.x.train.data5,Female.x.train.data6,Female.x.train.data7,Female.x.train.data8)

Female.list.train.y <- list(Female.y.train.data1,Female.y.train.data2,Female.y.train.data3,Female.y.train.data4,Female.y.train.data5,Female.y.train.data6,Female.y.train.data7,Female.y.train.data8)

```

Create a list for 8 testing data sets for male and female
```{r}
Male.list.test.x <- list(Male.x.test.data1,Male.x.test.data2,Male.x.test.data3,Male.x.test.data4,Male.x.test.data5,Male.x.test.data6,Male.x.test.data7,Male.x.test.data8)

Male.list.test.y <- list(Male.y.test.data1,Male.y.test.data2,Male.y.test.data3,Male.y.test.data4,Male.y.test.data5,Male.y.test.data6,Male.y.test.data7,Male.y.test.data8)

Female.list.test.x <- list(Female.x.test.data1,Female.x.test.data2,Female.x.test.data3,Female.x.test.data4,Female.x.test.data5,Female.x.test.data6,Female.x.test.data7,Female.x.test.data8)

Female.list.test.y <- list(Female.y.test.data1,Female.y.test.data2,Female.y.test.data3,Female.y.test.data4,Female.y.test.data5,Female.y.test.data6,Female.y.test.data7,Female.y.test.data8)
```


#### Modeling with sex


baseline model using leave one out for male
```{r}
set.seed(24)
list.of.coefs.male <- list()
list.of.fits.baseline.male <- list()
for (i in 1:8) {
# Cross validation to get best lambda
elnet.cv <- cv.glmnet(Male.list.train.x[[i]], Male.list.train.y[[i]]$Age, family="gaussian", alpha = 0.5, nfolds=10)

# Now get best model with defined parameters
fit <- glmnet(Male.list.train.x[[i]], Male.list.train.y[[i]]$Age, family = "gaussian", alpha = 0.5, lambda = elnet.cv$lambda.min)

#save the model in the list
list.of.fits.baseline.male[[i]] <- fit

coefs <- coef(fit)

# Remove coefficients that are 0
coefs <- as.data.frame(coefs[which(coefs!=0),])

# Tidy naming and export
names(coefs)[1] <- "Coefficient"
coefs$CpG <- rownames(coefs)
coefs <- coefs[,c("CpG", "Coefficient")]

list.of.coefs.male[[i]] <- coefs

}
```

baseline model using leave one out for female
```{r}
set.seed(24)
list.of.coefs.female <- list()
list.of.fits.baseline.female <- list()
for (i in 1:8) {
  # Cross validation to get best lambda
  elnet.cv <- cv.glmnet(Female.list.train.x[[i]], Female.list.train.y[[i]]$Age, family="gaussian", alpha = 0.5, nfolds=10)
  
  # Now get best model with defined parameters
  fit <- glmnet(Female.list.train.x[[i]], Female.list.train.y[[i]]$Age, family = "gaussian", alpha = 0.5, lambda = elnet.cv$lambda.min)
  
  #save the model in the list
  list.of.fits.baseline.female[[i]] <- fit
  
  coefs <- coef(fit)
  
  # Remove coefficients that are 0
  coefs <- as.data.frame(coefs[which(coefs!=0),])
  
  # Tidy naming and export
  names(coefs)[1] <- "Coefficient"
  coefs$CpG <- rownames(coefs)
  coefs <- coefs[,c("CpG", "Coefficient")]
  
  list.of.coefs.female[[i]] <- coefs
  
}
```



#### New predictions

Predictions for 8 different cohorts for male and female
```{r}
list.of.pred.baseline.male <- list()
for (i in 1:8) {
list.of.pred.baseline.male[[i]] <- predict(list.of.fits.baseline.male[[i]],newx = Male.list.test.x[[i]])

}


list.of.pred.baseline.female <- list()
for (i in 1:8) {
list.of.pred.baseline.female[[i]] <- predict(list.of.fits.baseline.female[[i]],newx = Female.list.test.x[[i]])

}
```


RMSE for 8 different cohorts for male
```{r}
list.of.RMSE.baseline.male <- c()
for (i in 1:8) {
list.of.RMSE.baseline.male[i] <- RMSE(list.of.pred.baseline.male[[i]],Male.list.test.y[[i]]$Age)
}

list.of.RMSE.baseline.male
```

RMSE for 8 different cohorts for female
```{r}
list.of.RMSE.baseline.female <- c()
for (i in 1:8) {
list.of.RMSE.baseline.female[i] <- RMSE(list.of.pred.baseline.female[[i]],Female.list.test.y[[i]]$Age)
}

list.of.RMSE.baseline.female
```



prediction for the whole data set for male and female
```{r}
pred.baseline.for.all.male <- rbind(list.of.pred.baseline.male[[1]],list.of.pred.baseline.male[[2]],list.of.pred.baseline.male[[3]],list.of.pred.baseline.male[[4]],list.of.pred.baseline.male[[5]],list.of.pred.baseline.male[[6]],list.of.pred.baseline.male[[7]],list.of.pred.baseline.male[[8]])

pred.baseline.for.all.female <- rbind(list.of.pred.baseline.female[[1]],list.of.pred.baseline.female[[2]],list.of.pred.baseline.female[[3]],list.of.pred.baseline.female[[4]],list.of.pred.baseline.female[[5]],list.of.pred.baseline.female[[6]],list.of.pred.baseline.female[[7]],list.of.pred.baseline.female[[8]])
```

Sanity check for prediction data sets
```{r}
identical(rownames(pred.baseline.for.all.male), rownames(Male.data))

identical(rownames(pred.baseline.for.all.female), rownames(Female.data))
```

RMSE for male and female
```{r}
RMSE(pred.baseline.for.all.male,Male.data$Age)

RMSE(pred.baseline.for.all.female,Female.data$Age)
```

get the new predicition and observation
```{r}
new.pred.all <- rbind(pred.baseline.for.all.male,pred.baseline.for.all.female)
new.true.all <- rbind(Male.data,Female.data)
```

the overall RMSE
```{r}
RMSE(new.pred.all,new.true.all$Age)
```

plot the new prediction by sex
```{r}
par(mfrow = c(1, 2))

plot(pred.baseline.for.all.male, Male.data$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data sex separated (male)",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.baseline.for.all.male,Male.data$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.baseline.for.all.male,Male.data$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)


plot(pred.baseline.for.all.female, Female.data$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data sex separated \n (female)",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.baseline.for.all.female,Female.data$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.baseline.for.all.female,Female.data$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)
```

plot the new overall prediction
```{r}
plot(new.pred.all, new.true.all$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data sex separated",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(new.pred.all,new.true.all$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(new.pred.all,new.true.all$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)
```




## 3.2 Best alpha model

Find the best alpha
```{r}
set.seed(24)
pred.best.alpha <- c()
list.of.fits <- list()
for (i in 0:10) {
  ## Here's what's going on in this loop...
  ## We are testing alpha = i/10. This means we are testing
  ## alpha = 0/10 = 0 on the first iteration, alpha = 1/10 = 0.1 on
  ## the second iteration etc.
  
  ## First, make a variable name that we can use later to refer
  ## to the model optimized for a specific alpha.
  ## For example, when alpha = 0, we will be able to refer to 
  ## that model with the variable name "alpha0".
  for (j in 1:8) {
  fit.name <- paste0("model",j," alpha", i/10)
  
  ## Now fit a model (i.e. optimize lambda) and store it in a list that 
  ## uses the variable name we just created as the reference.
  list.of.fits[[fit.name]] <-
    cv.glmnet(list.train.x[[j]], list.train.y[[j]]$Age, family="gaussian", alpha = i/10, nfolds=10)
}}


## Now we see which alpha (0, 0.1, ... , 0.9, 1) does the best job

## predicting the values in the Testing dataset.
for (i in 0:10) {
  for (j in 1:8) {
  fit.name <- paste0("model",j," alpha", i/10)
  
  ## Use each model to predict 'y' given the Testing dataset
  predicted <- data.frame(
    predict(list.of.fits[[fit.name]], 
      s=list.of.fits[[fit.name]]$lambda.min, newx=list.test.x[[j]]))
  
  pred.best.alpha <- rbind(pred.best.alpha,predicted)
  }} 

#The overall RMSE for each alpha  
RMSE.best.alpha <- c()
for (i in 0:10) {
n=2675*i
myrmse <- RMSE(pred.best.alpha$s1[(1+n):(2675+n)],geo_samples$Age)
RMSE.best.alpha <- c(RMSE.best.alpha,myrmse)
}

Best.alpha <- data.frame(Alpha = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),RMSE = RMSE.best.alpha)

Best.alpha
```


wirie it to csv
```{r}
write.csv(Best.alpha, "Best.alpha.csv")
```

further finding best alpha
```{r}
set.seed(24)
pred.best.alpha.further.more <- c()
list.of.fits.further.more <- list()
for (i in 0:10) {
  ## Here's what's going on in this loop...
  ## We are testing alpha = i/100. This means we are testing
  ## alpha = 0/100 = 0 on the first iteration, alpha = 1/100 = 0.01 on
  ## the second iteration etc.
  
  ## First, make a variable name that we can use later to refer
  ## to the model optimized for a specific alpha.
  ## For example, when alpha = 0, we will be able to refer to 
  ## that model with the variable name "alpha0".
  for (j in 1:8) {
  fit.name <- paste0("model",j," alpha", i/100)
  
  ## Now fit a model (i.e. optimize lambda) and store it in a list that 
  ## uses the variable name we just created as the reference.
  list.of.fits.further.more[[fit.name]] <-
    cv.glmnet(list.train.x[[j]], list.train.y[[j]]$Age, family="gaussian", alpha = i/100, nfolds=10)
}}


## Now we see which alpha (0, 0.05, ... , 0.95, 1) does the best job

## predicting the values in the Testing dataset.
for (i in 0:10) {
  for (j in 1:8) {
  fit.name <- paste0("model",j," alpha", i/100)
  
  ## Use each model to predict 'y' given the Testing dataset
  predicted <- data.frame(
    predict(list.of.fits.further.more[[fit.name]], 
      s=list.of.fits.further.more[[fit.name]]$lambda.min, newx=list.test.x[[j]]))
  
  pred.best.alpha.further.more <- rbind(pred.best.alpha.further.more,predicted)
  }} 


#The overall RMSE for each alpha  
RMSE.best.alpha.further.more <- c()
for (i in 0:10) {
n=2675*i
myrmse <- RMSE(pred.best.alpha.further.more$s1[(1+n):(2675+n)],geo_samples$Age)
RMSE.best.alpha.further.more <- c(RMSE.best.alpha.further.more,myrmse)
}

Best.alpha.further.more <- data.frame(Alpha = c(0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1),RMSE = RMSE.best.alpha.further.more)

Best.alpha.further.more
```

write it to csv
```{r}
write.csv(Best.alpha.further.more, "Best.alpha.further.more.csv")
```

get the best alpha prediction
```{r}
pred.best.alpha.to.plot <- pred.best.alpha.further.more$s1[(1+8025):(2675+8025)]
```


write it to csv
```{r}
write.csv(pred.best.alpha.to.plot, "pred.best.alpha.to.plot.csv")
```


get the prediction back
```{r}
pred.best.alpha.to.plot <- read.csv("pred.best.alpha.to.plot.csv")
```

the overall RMSE
```{r}
RMSE(pred.best.alpha.to.plot$x,geo_samples$Age)
```

a list of each cohort's prediction
```{r}
list.of.best.alpha.pred <- list(pred.best.alpha.to.plot[geo_samples$GEO=='GSE40279',2],pred.best.alpha.to.plot[geo_samples$GEO=='GSE41169',2],pred.best.alpha.to.plot[geo_samples$GEO=='GSE42861',2],pred.best.alpha.to.plot[geo_samples$GEO=='GSE53740',2],pred.best.alpha.to.plot[geo_samples$GEO=='GSE72773',2],pred.best.alpha.to.plot[geo_samples$GEO=='GSE72775',2],pred.best.alpha.to.plot[geo_samples$GEO=='GSE72777',2],pred.best.alpha.to.plot[geo_samples$GEO=='GSE78874',2])
```

a list of each cohort's r
```{r}
list.of.r.best.alpha <- c()
for (i in 1:8) {
list.of.r.best.alpha[i] <- cor(list.of.best.alpha.pred[[i]],list.test.y[[i]]$Age)
}

list.of.r.best.alpha
```


a list of each cohort's RMSE
```{r}
list.of.RMSE.best.alpha <- c()
for (i in 1:8) {
list.of.RMSE.best.alpha[i] <- RMSE(list.of.best.alpha.pred[[i]],list.test.y[[i]]$Age)
}

list.of.RMSE.best.alpha
```

plot the prediction for each cohort
```{r}
par(mfrow = c(2, 4))
for (i in 1:8) {
plot(list.of.best.alpha.pred[[i]], list.test.y[[i]]$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[i],col=i+1,pch=19)
legend("topleft", legend=paste("r =",round(list.of.r.best.alpha[i],3),"(pv = 0.0)","\nRMSE =",round(list.of.RMSE.best.alpha[i],3)),bty = "n", pch=19, col=i+1,cex=0.63)
abline(a = 0, b = 1, lwd=2)

}


par()
```

plot the overall prediction
```{r}
plot(pred.best.alpha.to.plot$x, geo_samples$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.best.alpha.to.plot$x,geo_samples$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.best.alpha.to.plot$x,geo_samples$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)
```




## 3.3 PCA

do the pca
```{r}
pca1 <- prcomp(geo_methylation)

perc.expl <- pca1$sdev^2 / sum(pca1$sdev^2)
```

finding the optimal number of pc
```{r}
RMSE.different.perc <- c()
list.fo.n <- c()
for (i in 0:29) {
n =1
while(sum(perc.expl[1:n]) <= 0.7 +i*0.01) {

  # increment number by 1
  n = n + 1
}

list.fo.n <- c(list.fo.n,n)

a <- pca1$x[,1:n]

set.seed(24)
elnet.cv <- cv.glmnet(a, geo_samples$Age, family="gaussian", alpha = 0.5, nfolds=10)

pca1.pred <- predict(elnet.cv,s=elnet.cv$lambda.min, newx = a)

RMSE.different.perc <- c(RMSE.different.perc,RMSE(pca1.pred,geo_samples$Age))

}
```


add the 100% pc
```{r}
a <- pca1$x
set.seed(24)
elnet.cv <- cv.glmnet(a, geo_samples$Age, family="gaussian", alpha = 0.5, nfolds=10)

pca1.pred <- predict(elnet.cv,s=elnet.cv$lambda.min, newx = a)
```


add the 100% RMSE on
```{r}
RMSE.different.perc <- c(RMSE.different.perc,RMSE(pca1.pred,geo_samples$Age))
```


a list of number of pc
```{r}
list.fo.n <- c(list.fo.n,2674)
```


a % label
```{r}
perc.label <- c()
for (i in 0:30) {
per <- 70+i
perc.label <- c(perc.label,paste(per,"%"))
}

```


use a data frame to show the choosing process
```{r}
pca.number.com <- data.frame(percentage.of.variance.explained = perc.label,RMSE=RMSE.different.perc, number.of.component=list.fo.n)
```

write it to csv
```{r}
write.csv(pca.number.com, "pca.number.com.csv")
```


select the optimal number of pc
```{r}
final.pca <- pca1$x[,1:1396]
```


get the new train data
```{r}
x.train.pca1 <- final.pca[rownames(final.pca) %in% rownames(y.train.data1),]
x.train.pca2 <- final.pca[rownames(final.pca) %in% rownames(y.train.data2),]
x.train.pca3 <- final.pca[rownames(final.pca) %in% rownames(y.train.data3),]
x.train.pca4 <- final.pca[rownames(final.pca) %in% rownames(y.train.data4),]
x.train.pca5 <- final.pca[rownames(final.pca) %in% rownames(y.train.data5),]
x.train.pca6 <- final.pca[rownames(final.pca) %in% rownames(y.train.data6),]
x.train.pca7 <- final.pca[rownames(final.pca) %in% rownames(y.train.data7),]
x.train.pca8 <- final.pca[rownames(final.pca) %in% rownames(y.train.data8),]
```

get the new test data
```{r}
x.test.pca1 <- final.pca[rownames(final.pca) %in% rownames(y.test.data1),]
x.test.pca2 <- final.pca[rownames(final.pca) %in% rownames(y.test.data2),]
x.test.pca3 <- final.pca[rownames(final.pca) %in% rownames(y.test.data3),]
x.test.pca4 <- final.pca[rownames(final.pca) %in% rownames(y.test.data4),]
x.test.pca5 <- final.pca[rownames(final.pca) %in% rownames(y.test.data5),]
x.test.pca6 <- final.pca[rownames(final.pca) %in% rownames(y.test.data6),]
x.test.pca7 <- final.pca[rownames(final.pca) %in% rownames(y.test.data7),]
x.test.pca8 <- final.pca[rownames(final.pca) %in% rownames(y.test.data8),]
```


Create a list for 8 training data sets for x
```{r}
list.train.x.pca <- list(x.train.pca1,x.train.pca2,x.train.pca3,x.train.pca4,x.train.pca5,x.train.pca6,x.train.pca7,x.train.pca8)

```

Create a list for 8 testing data sets for x
```{r}
list.test.x.pca <- list(x.test.pca1,x.test.pca2,x.test.pca3,x.test.pca4,x.test.pca5,x.test.pca6,x.test.pca7,x.test.pca8)

```


A pca-elastic net model using leave one out 
```{r}
set.seed(24)
list.of.coefs.pca <- list()
list.of.fits.baseline.pca <- list()
for (i in 1:8) {
# Cross validation to get best lambda
elnet.cv <- cv.glmnet(list.train.x.pca[[i]], list.train.y[[i]]$Age, family="gaussian", alpha = 0.5, nfolds=10)

# Now get best model with defined parameters
fit <- glmnet(list.train.x.pca[[i]], list.train.y[[i]]$Age, family = "gaussian", alpha = 0.5, lambda = elnet.cv$lambda.min)

#save the model in the list
list.of.fits.baseline.pca[[i]] <- fit

coefs <- coef(fit)

# Remove coefficients that are 0
coefs <- as.data.frame(coefs[which(coefs!=0),])

# Tidy naming and export
names(coefs)[1] <- "Coefficient"
coefs$CpG <- rownames(coefs)
coefs <- coefs[,c("CpG", "Coefficient")]

list.of.coefs.pca[[i]] <- coefs

}
```

### Prediction

Predictions for 8 different cohorts
```{r}
list.of.pred.baseline.pca <- list()
for (i in 1:8) {
list.of.pred.baseline.pca[[i]] <- predict(list.of.fits.baseline.pca[[i]],newx = list.test.x.pca[[i]])

}
```



RMSE for 8 different cohorts
```{r}
list.of.RMSE.baseline.pca <- c()
for (i in 1:8) {
list.of.RMSE.baseline.pca[i] <- RMSE(list.of.pred.baseline.pca[[i]],list.test.y[[i]]$Age)
}

list.of.RMSE.baseline.pca
```


r for 8 different cohorts
```{r}
list.of.r.baseline.pca <- c()
for (i in 1:8) {
list.of.r.baseline.pca[i] <- cor(list.of.pred.baseline.pca[[i]],list.test.y[[i]]$Age)
}

list.of.r.baseline.pca
```



prediction for the whole data set
```{r}
pred.baseline.for.all.pca <- rbind(list.of.pred.baseline.pca[[1]],list.of.pred.baseline.pca[[2]],list.of.pred.baseline.pca[[3]],list.of.pred.baseline.pca[[4]],list.of.pred.baseline.pca[[5]],list.of.pred.baseline.pca[[6]],list.of.pred.baseline.pca[[7]],list.of.pred.baseline.pca[[8]])
```

Sanity check for prediction data sets
```{r}
identical(rownames(pred.baseline.for.all.pca), rownames(geo_samples))
```

the overall RMSE
```{r}
RMSE(pred.baseline.for.all.pca,geo_samples$Age)
```

### Plot


```{r}
cohort.name <- unique(geo_samples$GEO)
```

plot the prediction for each cohort
```{r}
par(mfrow = c(2, 4))
for (i in 1:8) {
plot(list.of.pred.baseline.pca[[i]], list.test.y[[i]]$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[i],col=i+1,pch=19)
legend("topleft", legend=paste("r =",round(list.of.r.baseline.pca[i],3),"(pv = 0.0)","\nRMSE =",round(list.of.RMSE.baseline.pca[i],3)),bty = "n", pch=19, col=i+1,cex=0.63)
abline(a = 0, b = 1, lwd=2)

}


par()
```

plot the overall prediction 
```{r}
plot(pred.baseline.for.all.pca, geo_samples$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data (PCA-elastic)",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.baseline.for.all.pca,geo_samples$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.baseline.for.all.pca,geo_samples$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)
```




### PCA-best alpha

to find the best alpha
```{r}
set.seed(24)
pred.best.alpha.pca <- c()
list.of.fits.pca <- list()
for (i in 0:10) {
  ## Here's what's going on in this loop...
  ## We are testing alpha = i/10. This means we are testing
  ## alpha = 0/10 = 0 on the first iteration, alpha = 1/10 = 0.1 on
  ## the second iteration etc.
  
  ## First, make a variable name that we can use later to refer
  ## to the model optimized for a specific alpha.
  ## For example, when alpha = 0, we will be able to refer to 
  ## that model with the variable name "alpha0".
  for (j in 1:8) {
  fit.name <- paste0("model",j," alpha", i/10)
  
  ## Now fit a model (i.e. optimize lambda) and store it in a list that 
  ## uses the variable name we just created as the reference.
  list.of.fits.pca[[fit.name]] <-
    cv.glmnet(list.train.x.pca[[j]], list.train.y[[j]]$Age, family="gaussian", alpha = i/10, nfolds=10)
}}


## Now we see which alpha (0, 0.1, ... , 0.9, 1) does the best job

## predicting the values in the Testing dataset.
for (i in 0:10) {
  for (j in 1:8) {
  fit.name <- paste0("model",j," alpha", i/10)
  
  ## Use each model to predict 'y' given the Testing dataset
  predicted <- data.frame(
    predict(list.of.fits.pca[[fit.name]], 
      s=list.of.fits.pca[[fit.name]]$lambda.min, newx=list.test.x.pca[[j]]))
  
  pred.best.alpha.pca <- rbind(pred.best.alpha.pca,predicted)
  }} 

#The overall RMSE for each alpha  
RMSE.best.alpha.pca <- c()
for (i in 0:10) {
n=2675*i
myrmse <- RMSE(pred.best.alpha.pca$s1[(1+n):(2675+n)],geo_samples$Age)
RMSE.best.alpha.pca <- c(RMSE.best.alpha.pca,myrmse)
}

Best.alpha.pca <- data.frame(Alpha = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),RMSE = RMSE.best.alpha.pca)

Best.alpha.pca
```


write it to csv
```{r}
write.csv(Best.alpha.pca, "Best.alpha.pca.csv")
```

further finding
```{r}
set.seed(24)
pred.best.alpha.further.more.pca <- c()
list.of.fits.further.more.pca <- list()
for (i in 10:20) {
  ## Here's what's going on in this loop...
  ## We are testing alpha = i/20. This means we are testing
  ## alpha = 10/100 = 0.1 on the first iteration, alpha = 11/100 = 0.11 on
  ## the second iteration etc.
  
  ## First, make a variable name that we can use later to refer
  ## to the model optimized for a specific alpha.
  ## For example, when alpha = 0, we will be able to refer to 
  ## that model with the variable name "alpha0".
  for (j in 1:8) {
  fit.name <- paste0("model",j," alpha", i/100)
  
  ## Now fit a model (i.e. optimize lambda) and store it in a list that 
  ## uses the variable name we just created as the reference.
  list.of.fits.further.more.pca[[fit.name]] <-
    cv.glmnet(list.train.x.pca[[j]], list.train.y[[j]]$Age, family="gaussian", alpha = i/100, nfolds=10)
}}


## Now we see which alpha (0, 0.05, ... , 0.95, 1) does the best job

## predicting the values in the Testing dataset.
for (i in 10:20) {
  for (j in 1:8) {
  fit.name <- paste0("model",j," alpha", i/100)
  
  ## Use each model to predict 'y' given the Testing dataset
  predicted <- data.frame(
    predict(list.of.fits.further.more.pca[[fit.name]], 
      s=list.of.fits.further.more.pca[[fit.name]]$lambda.min, newx=list.test.x.pca[[j]]))
  
  pred.best.alpha.further.more.pca <- rbind(pred.best.alpha.further.more.pca,predicted)
  }} 


#The overall RMSE for each alpha  
RMSE.best.alpha.further.more.pca <- c()
for (i in 0:10) {
n=2675*i
myrmse <- RMSE(pred.best.alpha.further.more.pca$s1[(1+n):(2675+n)],geo_samples$Age)
RMSE.best.alpha.further.more.pca <- c(RMSE.best.alpha.further.more.pca,myrmse)
}

Best.alpha.further.more.pca <- data.frame(Alpha = c(0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2),RMSE = RMSE.best.alpha.further.more.pca)

Best.alpha.further.more.pca
```


write it to csv
```{r}
write.csv(Best.alpha.further.more.pca, "Best.alpha.further.more.pca.csv")
```


another further finding
```{r}
set.seed(24)
pred.best.alpha.further.more.pca <- c()
list.of.fits.further.more.pca <- list()
for (i in 20:30) {
  ## Here's what's going on in this loop...
  ## We are testing alpha = i/100. This means we are testing
  ## alpha = 20/100 = 0.2 on the first iteration, alpha = 21/100 = 0.21 on
  ## the second iteration etc.
  
  ## First, make a variable name that we can use later to refer
  ## to the model optimized for a specific alpha.
  ## For example, when alpha = 0, we will be able to refer to 
  ## that model with the variable name "alpha0".
  for (j in 1:8) {
  fit.name <- paste0("model",j," alpha", i/100)
  
  ## Now fit a model (i.e. optimize lambda) and store it in a list that 
  ## uses the variable name we just created as the reference.
  list.of.fits.further.more.pca[[fit.name]] <-
    cv.glmnet(list.train.x.pca[[j]], list.train.y[[j]]$Age, family="gaussian", alpha = i/100, nfolds=10)
}}


## Now we see which alpha (0, 0.05, ... , 0.95, 1) does the best job

## predicting the values in the Testing dataset.
for (i in 20:30) {
  for (j in 1:8) {
  fit.name <- paste0("model",j," alpha", i/100)
  
  ## Use each model to predict 'y' given the Testing dataset
  predicted <- data.frame(
    predict(list.of.fits.further.more.pca[[fit.name]], 
      s=list.of.fits.further.more.pca[[fit.name]]$lambda.min, newx=list.test.x.pca[[j]]))
  
  pred.best.alpha.further.more.pca <- rbind(pred.best.alpha.further.more.pca,predicted)
  }} 


#The overall RMSE for each alpha  
RMSE.best.alpha.further.more.pca <- c()
for (i in 0:10) {
n=2675*i
myrmse <- RMSE(pred.best.alpha.further.more.pca$s1[(1+n):(2675+n)],geo_samples$Age)
RMSE.best.alpha.further.more.pca <- c(RMSE.best.alpha.further.more.pca,myrmse)
}

Best.alpha.further.more.pca <- data.frame(Alpha = c(0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3),RMSE = RMSE.best.alpha.further.more.pca)

Best.alpha.further.more.pca
```


write it to csv
```{r}
write.csv(Best.alpha.further.more.pca, "Best.alpha.further.more.pca2.csv")
```

## 4. delete the worst cohort

### Modeling

A baseline model using leave one out 
```{r}
set.seed(24)
list.of.coefs <- list()
list.of.fits.baseline <- list()
for (i in 1:7) {
# Cross validation to get best lambda
elnet.cv <- cv.glmnet(list.train.x[[i]], list.train.y[[i]]$Age, family="gaussian", alpha = 0.5, nfolds=10)

# Now get best model with defined parameters
fit <- glmnet(list.train.x[[i]], list.train.y[[i]]$Age, family = "gaussian", alpha = 0.5, lambda = elnet.cv$lambda.min)

#save the model in the list
list.of.fits.baseline[[i]] <- fit

coefs <- coef(fit)

# Remove coefficients that are 0
coefs <- as.data.frame(coefs[which(coefs!=0),])

# Tidy naming and export
names(coefs)[1] <- "Coefficient"
coefs$CpG <- rownames(coefs)
coefs <- coefs[,c("CpG", "Coefficient")]

list.of.coefs[[i]] <- coefs

}
```


Predictions for 7 different cohorts
```{r}
list.of.pred.baseline <- list()
for (i in 1:7) {
list.of.pred.baseline[[i]] <- predict(list.of.fits.baseline[[i]],newx = list.test.x[[i]])

}
```


RMSE for 7 different cohorts
```{r}
list.of.RMSE.baseline <- c()
for (i in 1:7) {
list.of.RMSE.baseline[i] <- RMSE(list.of.pred.baseline[[i]],list.test.y[[i]]$Age)
}

list.of.RMSE.baseline
```


r for 7 different cohorts
```{r}
list.of.r.baseline <- c()
for (i in 1:7) {
list.of.r.baseline[i] <- cor(list.of.pred.baseline[[i]],list.test.y[[i]]$Age)
}

list.of.r.baseline
```



prediction for the whole data set
```{r}
pred.baseline.for.all <- rbind(list.of.pred.baseline[[1]],list.of.pred.baseline[[2]],list.of.pred.baseline[[3]],list.of.pred.baseline[[4]],list.of.pred.baseline[[5]],list.of.pred.baseline[[6]],list.of.pred.baseline[[7]])
```

Sanity check for prediction data sets
```{r}
identical(rownames(pred.baseline.for.all), rownames(geo_samples[geo_samples$GEO != 'GSE78874',]))
```

the overall RMSE for the 7 cohorts
```{r}
RMSE(pred.baseline.for.all,geo_samples[geo_samples$GEO != 'GSE78874',]$Age)
```

### Plot

```{r}
cohort.name <- unique(geo_samples$GEO)
```

plot the prediction for each cohort
```{r}
par(mfrow = c(2, 4))
for (i in 1:7) {
plot(list.of.pred.baseline[[i]], list.test.y[[i]]$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[i],col=i+1,pch=19)
legend("topleft", legend=paste("r =",round(list.of.r.baseline[i],3),"(pv = 0.0)","\nRMSE =",round(list.of.RMSE.baseline[i],3)),bty = "n", pch=19, col=i+1,cex=0.63)
abline(a = 0, b = 1, lwd=2)

}


par()
```

plot the overall prediction
```{r}
plot(pred.baseline.for.all, geo_samples[geo_samples$GEO != 'GSE78874',]$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data (GSE78874 removed)",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.baseline.for.all,geo_samples[geo_samples$GEO != 'GSE78874',]$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.baseline.for.all,geo_samples[geo_samples$GEO != 'GSE78874',]$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)
```


## 5. Cohort 7 and 8


Calculate the percentage for male and female for cohort 7 and 8
```{r}
df1 <- combined.data %>% 
  filter(GEO == "GSE72777") %>%
  group_by(Sex) %>% # Variable to be transformed
  count() %>% 
  ungroup() %>% 
  mutate(perc = `n` / sum(`n`)) %>% 
  arrange(perc) %>%
  mutate(labels = scales::percent(perc))


df2 <- combined.data %>% 
  filter(GEO == "GSE78874") %>%
  group_by(Sex) %>% # Variable to be transformed
  count() %>% 
  ungroup() %>% 
  mutate(perc = `n` / sum(`n`)) %>% 
  arrange(perc) %>%
  mutate(labels = scales::percent(perc))
```


Pie chart for Sex variable for the two cohorts
```{r}
ggplot(df1, aes(x = "", y = perc, fill = Sex)) +
  geom_col(color = "black") +
  geom_label(aes(label = labels),
            position = position_stack(vjust = 0.5),
            show.legend = FALSE) +
  guides(fill = guide_legend(title = "Sex")) +
  scale_fill_brewer() +
  coord_polar(theta = "y") + 
  theme_void() +
  ggtitle("Figure 6.1 Pie chart for Sex for cohort GSE72777")

ggplot(df2, aes(x = "", y = perc, fill = Sex)) +
  geom_col(color = "black") +
  geom_label(aes(label = labels),
            position = position_stack(vjust = 0.5),
            show.legend = FALSE) +
  guides(fill = guide_legend(title = "Sex")) +
  scale_fill_brewer() +
  coord_polar(theta = "y") + 
  theme_void() +
  ggtitle("Figure 6.4 Pie chart for Sex for cohort GSE78874")
```





Histogram for age distribution by sex for cohort GSE72777
```{r}
GSE72777.data <-  combined.data %>% 
  filter(GEO == "GSE72777")

  ggplot(GSE72777.data,aes(x = Age)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(Sex ~ ., scales = "free") +
  ggtitle("Figure 6.2 Histogram for age distribution by sex for cohort GSE72777")
```


Histogram for age distribution by sex for cohort GSE78874
```{r}
GSE78874.data <-  combined.data %>% 
  filter(GEO == "GSE78874")

  ggplot(GSE78874.data,aes(x = Age)) +
  geom_histogram(fill = "white", colour = "black") +
  facet_grid(Sex ~ ., scales = "free") +
  ggtitle("Figure 6.5 Histogram for age distribution by sex for cohort GSE78874")
```



Create 20 year age groups for GSE72777 and GSE78874
```{r}
GSE72777.data$AgeGroup <- cut(GSE72777.data$Age, 
                         breaks = c(-Inf,20,40,60,80,100,Inf) ,
                         
                         labels = c("0-19 years"
                                    ,"20-39 years",
                                    "40-59 years","60-79 years"
                                    ,"80-99 years","100+ years"),
                         right = FALSE)

GSE78874.data$AgeGroup <- cut(GSE78874.data$Age, 
                         breaks = c(-Inf,20,40,60,80,100,Inf) ,
                         
                         labels = c("0-19 years"
                                    ,"20-39 years",
                                    "40-59 years","60-79 years"
                                    ,"80-99 years","100+ years"),
                         right = FALSE)
```


Barplot for different age groups by sex for cohort GSE72777
```{r}
pl <- ggplot(data = GSE72777.data,aes(x = AgeGroup, fill =AgeGroup ))
pl <- pl + geom_bar()
pl <- pl + theme_minimal()
pl <- pl  + theme(axis.text.x = element_text(angle = 90,hjust =0 ))
pl <- pl + facet_grid(Sex ~ ., scales = "free")
pl <- pl + ggtitle("Figure 6.3 Barplot for different age groups by sex for cohort GSE72777 ")
pl
```

Barplot for different age groups by sex for cohort GSE78874
```{r}
pl <- ggplot(data = GSE78874.data,aes(x = AgeGroup, fill =AgeGroup ))
pl <- pl + geom_bar()
pl <- pl + theme_minimal()
pl <- pl  + theme(axis.text.x = element_text(angle = 90,hjust =0 ))
pl <- pl + facet_grid(Sex ~ ., scales = "free")
pl <- pl + ggtitle("Figure 6.6 Barplot for different age groups by sex for cohort GSE78874")
pl
```

A data frame showing the percentage of specific sex-agegroup for GSE72777 and GSE78874
```{r}
dfs1 <- GSE72777.data %>% 
  group_by(Sex, AgeGroup) %>% # Variable to be transformed
  count() %>% 
  ungroup() %>% 
  mutate(perc = `n` / sum(`n`)) %>% 
  arrange(perc) %>%
  mutate(labels = scales::percent(perc)) %>%
  arrange(Sex,AgeGroup)

dfs2 <- GSE78874.data %>% 
  group_by(Sex, AgeGroup) %>% # Variable to be transformed
  count() %>% 
  ungroup() %>% 
  mutate(perc = `n` / sum(`n`)) %>% 
  arrange(perc) %>%
  mutate(labels = scales::percent(perc)) %>%
  arrange(Sex,AgeGroup)
```


Shows the results
```{r}
dfs1

dfs2
```



Write it to a csv file
```{r}
write.csv(dfs1, "GSE72777.csv")

write.csv(dfs2, "GSE78874.csv")
```


### Age group data

The index of 5 age groups
```{r}
index.0.to.19years <- which(combined.data$AgeGroup == '0-19 years')

index.20.to.39years <- which(combined.data$AgeGroup == '20-39 years')

index.40.to.59years <- which(combined.data$AgeGroup == '40-59 years')

index.60.to.79years <- which(combined.data$AgeGroup == '60-79 years')
index.80.to.infyears <- which(combined.data$AgeGroup == '80+ years')


```


select the corrsponding age group data from the combined data set
```{r}
data.0.to.19years <- combined.data[index.0.to.19years,]

data.20.to.39years <- combined.data[index.20.to.39years,]

data.40.to.59years <- combined.data[index.40.to.59years,]

data.60.to.79years <- combined.data[index.60.to.79years,]

data.80.to.infyears <- combined.data[index.80.to.infyears,]


```


## 6. New cross validation

Randomly split the five age group data set into 8 parts and save them in a list
```{r}
set.seed(24)
list1 <- split(data.0.to.19years, sample(rep(1:8,times=c(5,5,5,5,5,5,5,4))))
list2 <- split(data.20.to.39years, sample(rep(1:8,times=c(32,32,33,32,33,32,33,32))))
list3 <- split(data.40.to.59years, sample(rep(1:8,times=c(100,100,100,100,100,100,100,100))))
list4 <- split(data.60.to.79years, sample(rep(1:8,times=c(164,164,165,164,165,164,165,164))))
list5 <- split(data.80.to.infyears, sample(rep(1:8,times=c(33,32,33,33,33,33,32,33))))
```

Combine the data from different age groups
```{r}
data.1 <- rbind(list1[[1]],list2[[1]],list3[[1]],list4[[1]],list5[[1]])
data.2 <- rbind(list1[[2]],list2[[2]],list3[[2]],list4[[2]],list5[[2]])
data.3 <- rbind(list1[[3]],list2[[3]],list3[[3]],list4[[3]],list5[[3]])
data.4 <- rbind(list1[[4]],list2[[4]],list3[[4]],list4[[4]],list5[[4]])
data.5 <- rbind(list1[[5]],list2[[5]],list3[[5]],list4[[5]],list5[[5]])
data.6 <- rbind(list1[[6]],list2[[6]],list3[[6]],list4[[6]],list5[[6]])
data.7 <- rbind(list1[[7]],list2[[7]],list3[[7]],list4[[7]],list5[[7]])
data.8 <- rbind(list1[[8]],list2[[8]],list3[[8]],list4[[8]],list5[[8]])

```

The whole data set
```{r}
overall.data <- rbind(data.1,data.2,data.3,data.4,data.5,data.6,data.7,data.8)
```

Testing data for x and y
```{r}
x.test1 <- data.1[,-c(1:3,23762)]
x.test2 <- data.2[,-c(1:3,23762)]
x.test3 <- data.3[,-c(1:3,23762)]
x.test4 <- data.4[,-c(1:3,23762)]
x.test5 <- data.5[,-c(1:3,23762)]
x.test6 <- data.6[,-c(1:3,23762)]
x.test7 <- data.7[,-c(1:3,23762)]
x.test8 <- data.8[,-c(1:3,23762)]

y.test1 <- data.1[,c(1:3,23762)]
y.test2 <- data.2[,c(1:3,23762)]
y.test3 <- data.3[,c(1:3,23762)]
y.test4 <- data.4[,c(1:3,23762)]
y.test5 <- data.5[,c(1:3,23762)]
y.test6 <- data.6[,c(1:3,23762)]
y.test7 <- data.7[,c(1:3,23762)]
y.test8 <- data.8[,c(1:3,23762)]
```

Make x to matrix
```{r}
x.test1 <- as.matrix(x.test1)
x.test2 <- as.matrix(x.test2)
x.test3 <- as.matrix(x.test3)
x.test4 <- as.matrix(x.test4)
x.test5 <- as.matrix(x.test5)
x.test6 <- as.matrix(x.test6)
x.test7 <- as.matrix(x.test7)
x.test8 <- as.matrix(x.test8)
```


Sanity check for testing data sets
```{r}
identical(rownames(x.test1), rownames(y.test1))
identical(rownames(x.test2), rownames(y.test2))
identical(rownames(x.test3), rownames(y.test3))
identical(rownames(x.test4), rownames(y.test4))
identical(rownames(x.test5), rownames(y.test5))
identical(rownames(x.test6), rownames(y.test6))
identical(rownames(x.test7), rownames(y.test7))
identical(rownames(x.test8), rownames(y.test8))

```

The 8 traning x
```{r}
`%!in%` <- Negate(`%in%`)

x.train1 <- geo_methylation[rownames(geo_methylation) %!in% rownames(x.test1),]
x.train2 <- geo_methylation[rownames(geo_methylation) %!in% rownames(x.test2),]
x.train3 <- geo_methylation[rownames(geo_methylation) %!in% rownames(x.test3),]
x.train4 <- geo_methylation[rownames(geo_methylation) %!in% rownames(x.test4),]
x.train5 <- geo_methylation[rownames(geo_methylation) %!in% rownames(x.test5),]
x.train6 <- geo_methylation[rownames(geo_methylation) %!in% rownames(x.test6),]
x.train7 <- geo_methylation[rownames(geo_methylation) %!in% rownames(x.test7),]
x.train8 <- geo_methylation[rownames(geo_methylation) %!in% rownames(x.test8),]
```


The 8 traning y
```{r}
y.train1 <- combined.data[rownames(combined.data) %!in% rownames(y.test1),c(1:3,23762)]
y.train2 <- combined.data[rownames(combined.data) %!in% rownames(y.test2),c(1:3,23762)]
y.train3 <- combined.data[rownames(combined.data) %!in% rownames(y.test3),c(1:3,23762)]
y.train4 <- combined.data[rownames(combined.data) %!in% rownames(y.test4),]
y.train5 <- combined.data[rownames(combined.data) %!in% rownames(y.test5),c(1:3,23762)]
y.train6 <- combined.data[rownames(combined.data) %!in% rownames(y.test6),c(1:3,23762)]
y.train7 <- combined.data[rownames(combined.data) %!in% rownames(y.test7),c(1:3,23762)]
y.train8 <- combined.data[rownames(combined.data) %!in% rownames(y.test8),c(1:3,23762)]
```


Sanity check for training data sets
```{r}
identical(rownames(x.train1), rownames(y.train1))
identical(rownames(x.train2), rownames(y.train2))
identical(rownames(x.train3), rownames(y.train3))
identical(rownames(x.train4), rownames(y.train4))
identical(rownames(x.train5), rownames(y.train5))
identical(rownames(x.train6), rownames(y.train6))
identical(rownames(x.train7), rownames(y.train7))
identical(rownames(x.train8), rownames(y.train8))

```

make a list to save trainning data
```{r}
list.x.train <- list(x.train1,x.train2,x.train3,x.train4,x.train5,x.train6,x.train7,x.train8)

list.y.train <- list(y.train1,y.train2,y.train3,y.train4,y.train5,y.train6,y.train7,y.train8)
```

make a list to save testing data
```{r}
list.x.test <- list(x.test1,x.test2,x.test3,x.test4,x.test5,x.test6,x.test7,x.test8)

list.y.test <- list(y.test1,y.test2,y.test3,y.test4,y.test5,y.test6,y.test7,y.test8)
```



#### Modeling

model again
```{r}
set.seed(24)
list.of.coefs.new.cross <- list()
list.of.fits..new.cross<- list()
for (i in 1:8) {
# Cross validation to get best lambda
elnet.cv <- cv.glmnet(list.x.train[[i]], list.y.train[[i]]$Age, family="gaussian", alpha = 0.5, nfolds=10)

# Now get best model with defined parameters
fit <- glmnet(list.x.train[[i]], list.y.train[[i]]$Age, family = "gaussian", alpha = 0.5, lambda = elnet.cv$lambda.min)

#save the model in the list
list.of.fits..new.cross[[i]] <- fit

coefs <- coef(fit)

# Remove coefficients that are 0
coefs <- as.data.frame(coefs[which(coefs!=0),])

# Tidy naming and export
names(coefs)[1] <- "Coefficient"
coefs$CpG <- rownames(coefs)
coefs <- coefs[,c("CpG", "Coefficient")]

list.of.coefs.new.cross[[i]] <- coefs

}
```


#### Prediction

Predictions for 8 different data sets
```{r}
list.of.pred.new.cross <- list()
for (i in 1:8) {
list.of.pred.new.cross[[i]] <- predict(list.of.fits..new.cross[[i]],newx = list.x.test[[i]])

}
```

Combine the predictions together
```{r}
pred.new.cross.model <- rbind(list.of.pred.new.cross[[1]],list.of.pred.new.cross[[2]],list.of.pred.new.cross[[3]],list.of.pred.new.cross[[4]],list.of.pred.new.cross[[5]],list.of.pred.new.cross[[6]],list.of.pred.new.cross[[7]],list.of.pred.new.cross[[8]])
```

write the predictions to csv file
```{r}
write.csv(pred.new.cross.model, "pred.new.cross.csv")
```


get the corresponding observed values
```{r}
obs.new.cross.model <- rbind(list.y.test[[1]],list.y.test[[2]],list.y.test[[3]],list.y.test[[4]],list.y.test[[5]],list.y.test[[6]],list.y.test[[7]],list.y.test[[8]])
```

write the corresponding observed values to csv file
```{r}
write.csv(obs.new.cross.model, "obs.new.cross.csv")
```


The observed values for the 8 different cohorts
```{r}
obs.GSE40279 <- obs.new.cross.model[which(obs.new.cross.model$GEO == 'GSE40279'),]
obs.GSE41169 <- obs.new.cross.model[which(obs.new.cross.model$GEO == 'GSE41169'),]
obs.GSE42861 <- obs.new.cross.model[which(obs.new.cross.model$GEO == 'GSE42861'),]
obs.GSE53740 <- obs.new.cross.model[which(obs.new.cross.model$GEO == 'GSE53740'),]
obs.GSE72773 <- obs.new.cross.model[which(obs.new.cross.model$GEO == 'GSE72773'),]
obs.GSE72775 <- obs.new.cross.model[which(obs.new.cross.model$GEO == 'GSE72775'),]
obs.GSE72777 <- obs.new.cross.model[which(obs.new.cross.model$GEO == 'GSE72777'),]
obs.GSE78874 <- obs.new.cross.model[which(obs.new.cross.model$GEO == 'GSE78874'),]
```


The new predictions using new cross model for the 8 different cohorts
```{r}
pre.new.cross.GSE40279 <- data.frame(pred.new.cross.model[rownames(pred.new.cross.model) %in% rownames(obs.GSE40279),])
pre.new.cross.GSE41169 <- data.frame(pred.new.cross.model[rownames(pred.new.cross.model) %in% rownames(obs.GSE41169),])
pre.new.cross.GSE42861 <- data.frame(pred.new.cross.model[rownames(pred.new.cross.model) %in% rownames(obs.GSE42861),])
pre.new.cross.GSE53740 <- data.frame(pred.new.cross.model[rownames(pred.new.cross.model) %in% rownames(obs.GSE53740),])
pre.new.cross.GSE72773 <- data.frame(pred.new.cross.model[rownames(pred.new.cross.model) %in% rownames(obs.GSE72773),])
pre.new.cross.GSE72775 <- data.frame(pred.new.cross.model[rownames(pred.new.cross.model) %in% rownames(obs.GSE72775),])
pre.new.cross.GSE72777 <- data.frame(pred.new.cross.model[rownames(pred.new.cross.model) %in% rownames(obs.GSE72777),])
pre.new.cross.GSE78874 <- data.frame(pred.new.cross.model[rownames(pred.new.cross.model) %in% rownames(obs.GSE78874),])
```





RMSE for the 8 different cohorts
```{r}
eight.cohorts.RMSE.new.cross <-data.frame(New.RMSE.consistent=c(RMSE(pre.new.cross.GSE40279[,1],obs.GSE40279$Age),RMSE(pre.new.cross.GSE41169[,1],obs.GSE41169$Age),RMSE(pre.new.cross.GSE42861[,1],obs.GSE42861$Age),RMSE(pre.new.cross.GSE53740[,1],obs.GSE53740$Age),RMSE(pre.new.cross.GSE72773[,1],obs.GSE72773$Age),RMSE(pre.new.cross.GSE72775[,1],obs.GSE72775$Age),RMSE(pre.new.cross.GSE72777[,1],obs.GSE72777$Age),RMSE(pre.new.cross.GSE78874[,1],obs.GSE78874$Age)))


eight.cohorts.RMSE.new.cross$New.RMSE.consistent
```



RMSE for 8 different data sets
```{r}
list.of.RMSE.new.cross <- c()
for (i in 1:8) {
list.of.RMSE.new.cross[i] <- RMSE(list.of.pred.new.cross[[i]],list.y.test[[i]]$Age)
}

list.of.RMSE.new.cross
```

prediction for the whole data set
```{r}
pred.new.cross.for.all <- rbind(list.of.pred.new.cross[[1]],list.of.pred.new.cross[[2]],list.of.pred.new.cross[[3]],list.of.pred.new.cross[[4]],list.of.pred.new.cross[[5]],list.of.pred.new.cross[[6]],list.of.pred.new.cross[[7]],list.of.pred.new.cross[[8]])
```

Sanity check for prediction data sets
```{r}
identical(rownames(pred.new.cross.for.all), rownames(overall.data))
```

Shows the overall RMSE
```{r}
RMSE(pred.new.cross.for.all,overall.data$Age)
```




#### Pred vs obs plot

```{r}
cohort.name <- unique(geo_samples$GEO)
```

plot the prediction for each cohort
```{r}
par(mfrow = c(2, 4))

plot(pre.new.cross.GSE40279[,1], obs.GSE40279$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[1],col=2,pch=19)
legend("topleft", legend=paste("r =",round(cor(pre.new.cross.GSE40279[,1], obs.GSE40279$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pre.new.cross.GSE40279[,1], obs.GSE40279$Age),3)),bty = "n", pch=19, col=2,cex=0.63)
abline(a = 0, b = 1, lwd=2)

plot(pre.new.cross.GSE41169[,1], obs.GSE41169$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[2],col=3,pch=19)
legend("topleft", legend=paste("r =",round(cor(pre.new.cross.GSE41169[,1], obs.GSE41169$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pre.new.cross.GSE41169[,1], obs.GSE41169$Age),3)),bty = "n", pch=19, col=3,cex=0.63)
abline(a = 0, b = 1, lwd=2)

plot(pre.new.cross.GSE42861[,1], obs.GSE42861$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[3],col=4,pch=19)
legend("topleft", legend=paste("r =",round(cor(pre.new.cross.GSE42861[,1], obs.GSE42861$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pre.new.cross.GSE42861[,1], obs.GSE42861$Age),3)),bty = "n", pch=19, col=4,cex=0.63)
abline(a = 0, b = 1, lwd=2)

plot(pre.new.cross.GSE53740[,1], obs.GSE53740$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[4],col=5,pch=19)
legend("topleft", legend=paste("r =",round(cor(pre.new.cross.GSE53740[,1], obs.GSE53740$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pre.new.cross.GSE53740[,1], obs.GSE53740$Age),3)),bty = "n", pch=19, col=5,cex=0.63)
abline(a = 0, b = 1, lwd=2)

plot(pre.new.cross.GSE72773[,1], obs.GSE72773$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[5],col=6,pch=19)
legend("topleft", legend=paste("r =",round(cor(pre.new.cross.GSE72773[,1], obs.GSE72773$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pre.new.cross.GSE72773[,1], obs.GSE72773$Age),3)),bty = "n", pch=19, col=6,cex=0.63)
abline(a = 0, b = 1, lwd=2)

plot(pre.new.cross.GSE72775[,1], obs.GSE72775$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[6],col=7,pch=19)
legend("topleft", legend=paste("r =",round(cor(pre.new.cross.GSE72775[,1], obs.GSE72775$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pre.new.cross.GSE72775[,1], obs.GSE72775$Age),3)),bty = "n", pch=19, col=7,cex=0.63)
abline(a = 0, b = 1, lwd=2)

plot(pre.new.cross.GSE72777[,1], obs.GSE72777$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[7],col=8,pch=19)
legend("topleft", legend=paste("r =",round(cor(pre.new.cross.GSE72777[,1], obs.GSE72777$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pre.new.cross.GSE72777[,1], obs.GSE72777$Age),3)),bty = "n", pch=19, col=8,cex=0.63)
abline(a = 0, b = 1, lwd=2)

plot(pre.new.cross.GSE78874[,1], obs.GSE78874$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main=cohort.name[8],col=9,pch=19)
legend("topleft", legend=paste("r =",round(cor(pre.new.cross.GSE78874[,1], obs.GSE78874$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pre.new.cross.GSE78874[,1], obs.GSE78874$Age),3)),bty = "n", pch=19, col=9,cex=0.63)
abline(a = 0, b = 1, lwd=2)

par()
```


plot the overall prediction
```{r}
plot(pred.new.cross.for.all, overall.data$Age,
     xlab = "Predicted Age",
     ylab = "True Age",xlim=c(0,110),ylim=c(0,110),main="Whole data (mixed data)",col=21,pch=19)
legend("topleft", legend=paste("r =",round(cor(pred.new.cross.for.all,overall.data$Age),3),"(pv = 0.0)","\nRMSE =",round(RMSE(pred.new.cross.for.all,overall.data$Age),3)),bty = "n", pch=19, col=21,cex=1)
abline(a = 0, b = 1, lwd=2)
```

